{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICT STEPS:\n",
    "- load files [x]\n",
    "- load df [x]\n",
    "- predict zdif [x]\n",
    "- get dtm [x]\n",
    "- write raster [x]\n",
    "- merge block [-] \n",
    "    - check transitions manually [-]\n",
    "    -  if not, predict blovk [-]\n",
    "- use df to get error metrics \n",
    "- make plots histogram,lineplot,river-cross section \n",
    "- erro maps difference, rmse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from paths import libpath\n",
    "sys.path.append(libpath)\n",
    "from utilsdf import list_files_by_tilenames,tile_files_to_parquet_parallel\n",
    "from uvars import (tilenames_mkd, tilenames_tls,tilenames_rgn,\n",
    "                   tilenames_lidar,RES_DPATH)\n",
    "\n",
    "from uvars import aux_ending12,s1_ending12,s2_ending12,tar_ending12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-by tile per region predictions best:\n",
    "- RNG [x]\n",
    "- TLS [x]\n",
    "\n",
    "if can find the code from geotile to merge all over the faces would be great, use code like rive-floodpain merge to do $$\n",
    "\n",
    "\n",
    "-by block per region predictions:\n",
    "- TLS \n",
    "- RNG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E105/N09E105_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E106/N09E106_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E104/N10E104_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E105/N10E105_byldem.parquet\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E106/N10E106_byldem.parquet\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from utilsdf import check_fillnulls\n",
    "\n",
    "def get_parquets_and_geotifs_by_tile(RES_DPATH, X, tilenames,vending_all):\n",
    "    fparquet_list,tile_files_list = list_files_by_tilenames(RES_DPATH, X, tilenames)\n",
    "    assert len(fparquet_list) == len(tile_files_list), 'len(fparquet_list) != len(tile_files_list)'\n",
    "    _, fparquet_list = tile_files_to_parquet_parallel(tilenames, \n",
    "                                                       RES_DPATH, \n",
    "                                                       X, \n",
    "                                                       vending_all)\n",
    "    \n",
    "    return fparquet_list,tile_files_list   \n",
    "\n",
    "\n",
    "def write_predictions(predictions, tile_file, output_raster_path, block_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Writes predictions to a new raster file using metadata from an existing tile file in blocks,\n",
    "    optimised for large rasters.\n",
    "\n",
    "    Parameters:\n",
    "    - predictions (array-like): 1D array of predicted values matching the flattened raster size.\n",
    "    - tile_file (str): Path to the raster file from which metadata will be read.\n",
    "    - output_raster_path (str): Path where the new raster file will be saved.\n",
    "    - block_size (tuple): Tuple specifying the block size for processing (default is (128, 128)).\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Read metadata and raster dimensions from the tile file\n",
    "    with rasterio.open(tile_file) as src:\n",
    "        meta = src.meta.copy()\n",
    "        raster_shape = (src.height, src.width)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "\n",
    "    # Reshape predictions to match the raster's dimensions\n",
    "    try:\n",
    "        predictions_reshaped = np.array(predictions).reshape(raster_shape)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Predictions array size {len(predictions)} does not match raster dimensions {raster_shape}.\")\n",
    "\n",
    "    # Update metadata for writing a new raster\n",
    "    meta.update({\n",
    "        \"dtype\": rasterio.float32,  # Ensure predictions are stored as float32\n",
    "        \"count\": 1,  # Single band\n",
    "        \"compress\": \"lzw\"  # Optional: Add compression\n",
    "    })\n",
    "\n",
    "    # Write the new raster in blocks\n",
    "    with rasterio.open(output_raster_path, \"w\", **meta) as dst:\n",
    "        print(f\"Writing raster in blocks of size: {block_size}\")\n",
    "        for y_start in range(0, raster_shape[0], block_size[0]):\n",
    "            for x_start in range(0, raster_shape[1], block_size[1]):\n",
    "                # Calculate window bounds\n",
    "                y_end = min(y_start + block_size[0], raster_shape[0])\n",
    "                x_end = min(x_start + block_size[1], raster_shape[1])\n",
    "                window = ((y_start, y_end), (x_start, x_end))\n",
    "\n",
    "                # Slice the data for the current block\n",
    "                block_data = predictions_reshaped[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                # Write the block to the corresponding window\n",
    "                dst.write(block_data.astype(rasterio.float32), 1, window=rasterio.windows.Window.from_slices(*window))\n",
    "\n",
    "    print(f\"Raster written successfully to {output_raster_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def get_tile_file(tile_files):\n",
    "    tile_file = [i for i in tile_files if i.endswith('edem_W84.tif')] #[0]\n",
    "    assert len(tile_file) == 1, 'len(tile_file) != 1'\n",
    "    tile_file = tile_file[0]\n",
    "    return tile_file\n",
    "\n",
    "def load_prediction_data(fparquet,fcol):\n",
    "    df = pd.read_parquet(fparquet)\n",
    "    df[fcol] = check_fillnulls(df[fcol])\n",
    "    return df\n",
    "\n",
    "def load_cb_model(modelpath):\n",
    "    assert os.path.exists(modelpath), f'{modelpath} does not exist'\n",
    "    model = CatBoostRegressor()\n",
    "    model.load_model(modelpath)\n",
    "    return model\n",
    "\n",
    "def get_prediction_df(model,df,fcol,yvar,tcol):\n",
    "    df[f'ml_{yvar}'] = model.predict(Pool(df[fcol]))\n",
    "    df[f'ml_{tcol}'] = df[tcol].subtract(df[f'ml_{yvar}'])\n",
    "    return df\n",
    "\n",
    "def cb_predict_workflow(outdir,modelpath,fparquet,tile_files,\n",
    "                        fcol,yvar,tcol,ps,bsize=256):\n",
    "    tile_ifile = get_tile_file(tile_files)\n",
    "    tile_odir = os.path.join(outdir,tile_ifile.split('/')[-2])\n",
    "    os.makedirs(tile_odir,exist_ok=True)\n",
    "    tile_ofile = os.path.join(tile_odir,tile_ifile.split('/')[-1].replace('.tif','_ML.tif'))\n",
    "\n",
    "    if not os.path.isfile(tile_ofile):\n",
    "        f'writing:: {tile_ofile} ...'\n",
    "        df = load_prediction_data(fparquet,fcol)\n",
    "        assert len(df) == ps * ps, 'Grid size does not match'\n",
    "        model = load_cb_model(modelpath)\n",
    "        df = get_prediction_df(model,df,fcol,yvar,tcol)\n",
    "\n",
    "        \n",
    "        write_predictions(predictions=df[f'ml_{tcol}'], #\n",
    "                        tile_file=tile_ifile, \n",
    "                        output_raster_path=tile_ofile, \n",
    "                        block_size=(bsize, bsize))\n",
    "    else:\n",
    "        print(f'{tile_ofile} already exists')\n",
    "\n",
    "\n",
    "yvar = \"zdif\"\n",
    "tcol = 'edem_w84'\n",
    "rcol = 'multi_dtm_lidar'\n",
    "fcol = ['egm08', 'egm96', 'tdem_hem', 'multi_s1_band1', 'multi_s1_band2',\n",
    "        'multi_s2_band1', 'multi_s2_band2', 'multi_s2_band3']\n",
    "tar_ending,aux_ending,s1_ending,s2_ending = aux_ending12,s1_ending12,s2_ending12,tar_ending12\n",
    "vending_all = tar_ending+aux_ending+s1_ending+s2_ending\n",
    "X = 12 \n",
    "ps = 9001\n",
    "tilenames = tilenames_mkd\n",
    "bsize = 512 # match with grid size X \n",
    "modelpath = ''\n",
    "outdir = ''\n",
    "fparquet_list,tile_files_list = get_parquets_and_geotifs_by_tile(RES_DPATH, X, tilenames_mkd,vending_all)\n",
    "\n",
    "# for fparquet,tile_files in zip(fparquet_list,tile_files_list):\n",
    "#     cb_predict_workflow(outdir,modelpath,fparquet,tile_files,\n",
    "#                         fcol,yvar,tcol,ps,bsize=256)\n",
    "    \n",
    "## clean this code, and make it more modular and improve any thing that needs improvement\n",
    "## add timer per cb_predict_workflow \n",
    "# add timer for the whole process too see how long it takes to predict all the tiles\n",
    "# print the timer at the end and write both times to the log file txt t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter10000_n81000000_eq6xtile/catboost_10000_42_model.txt\"\n",
    "outdir = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def get_best_model(predictor):\n",
    "    \"\"\"\n",
    "    Safely retrieves the best model for a given AutoGluon predictor.\n",
    "\n",
    "    Args:\n",
    "        predictor (autogluon.tabular.TabularPredictor): The trained AutoGluon predictor.\n",
    "\n",
    "    Returns:\n",
    "        str: The name of the best model if available.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no models are available for inference.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the predictor is valid\n",
    "        if predictor is None:\n",
    "            raise ValueError(\"The predictor instance is None. Please provide a valid AutoGluon predictor.\")\n",
    "        \n",
    "        # Attempt to get the best model\n",
    "        best_model = predictor.model_best\n",
    "        if not best_model:\n",
    "            raise ValueError(\"No best model found. Ensure the predictor has been trained and contains models.\")\n",
    "        \n",
    "        return best_model\n",
    "    except AssertionError as e:\n",
    "        # Handle specific assertion errors\n",
    "        error_message = f\"AssertionError encountered: {e}. Ensure the predictor has fit models that can infer.\"\n",
    "        logging.error(error_message)\n",
    "        raise ValueError(error_message) from e\n",
    "    except Exception as e:\n",
    "        # Handle other unexpected errors\n",
    "        logging.error(f\"Unexpected error: {e}\")\n",
    "        raise\n",
    "\n",
    "def safe_predict(predictor, data):\n",
    "    \"\"\"\n",
    "    Safely makes predictions using a given AutoGluon predictor.\n",
    "\n",
    "    Args:\n",
    "        predictor (autogluon.tabular.TabularPredictor): The trained AutoGluon predictor.\n",
    "        data (pd.DataFrame): The input data for prediction.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The predictions.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no models are available or if data is invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the predictor and data are valid\n",
    "        if predictor is None:\n",
    "            raise ValueError(\"The predictor instance is None. Please provide a valid AutoGluon predictor.\")\n",
    "        \n",
    "        if data is None or data.empty:\n",
    "            raise ValueError(\"The input data is None or empty. Provide valid data for prediction.\")\n",
    "\n",
    "        # Attempt prediction\n",
    "        predictions = predictor.predict(data)\n",
    "        return predictions\n",
    "    except AssertionError as e:\n",
    "        # Handle specific assertion errors\n",
    "        error_message = f\"AssertionError encountered: {e}. Ensure the predictor has fit models and valid data.\"\n",
    "        logging.error(error_message)\n",
    "        raise ValueError(error_message) from e\n",
    "    except Exception as e:\n",
    "        # Handle other unexpected errors\n",
    "        logging.error(f\"Unexpected error during prediction: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ag_mbest_predict_workflow(outdir,dirname, modelpath,\n",
    "                             fparquet,tile_files,\n",
    "                            fcol,yvar,tcol,ps,bsize=256):\n",
    "    \n",
    "    predictor = TabularPredictor.load(modelpath)\n",
    "\n",
    "    # load the model first, and the perfom he cheks if not working, then dont even load the data \n",
    "    # if it passes then go one to load the data and make the predictions\n",
    "    \n",
    "    \n",
    "    outpath = os.path.join(outdir,dirname)\n",
    "    tile_ifile = get_tile_file(tile_files)\n",
    "    tile_odir = os.path.join(outpath,tile_ifile.split('/')[-2])\n",
    "    os.makedirs(tile_odir,exist_ok=True)\n",
    "    tile_ofile = os.path.join(tile_odir,tile_ifile.split('/')[-1].replace('.tif','_ML.tif'))\n",
    "\n",
    "    if not os.path.isfile(tile_ofile):\n",
    "        f'writing:: {tile_ofile} ...'\n",
    "        df = load_prediction_data(fparquet,fcol)\n",
    "        assert len(df) == ps * ps, 'Grid size does not match'\n",
    "      \n",
    "        df[f'ml_{yvar}'] = predictor.predict(df[fcol])\n",
    "        df[f'ml_{tcol}'] = df[tcol].subtract(df[f'ml_{yvar}'])\n",
    "\n",
    "        \n",
    "        write_predictions(predictions=df[f'ml_{tcol}'], #\n",
    "                        tile_file=tile_ifile, \n",
    "                        output_raster_path=tile_ofile, \n",
    "                        block_size=(bsize, bsize))\n",
    "    else:\n",
    "        print(f'{tile_ofile} already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "fparquet,tile_files  = fparquet_list[0],tile_files_list[0] \n",
    "#df = load_prediction_data(fparquet,fcol)\n",
    "#assert len(df) == ps * ps, 'Grid size does not match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath_ag = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit1140_best_quality_135000000/\"\n",
    "#modelpath_ag = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit1140_best_quality_135000000/models/trainer.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "def ag_mbest_predict_workflow(outdir, dirname, modelpath, \n",
    "                              fparquet, tile_files, \n",
    "                              fcol, yvar, tcol, ps, bsize=256):\n",
    "    \"\"\"\n",
    "    Workflow to perform predictions using a pre-trained model. The function checks \n",
    "    the model before loading the data to avoid unnecessary costs if the model is invalid.\n",
    "\n",
    "    Args:\n",
    "        outdir (str): Output directory path.\n",
    "        dirname (str): Directory name for organising outputs.\n",
    "        modelpath (str): Path to the saved model.\n",
    "        fparquet (str): Path to the input parquet file containing prediction data.\n",
    "        tile_files (list): List of tile files.\n",
    "        fcol (str): Feature column used for predictions.\n",
    "        yvar (str): Variable to predict.\n",
    "        tcol (str): Target column.\n",
    "        ps (int): Grid size parameter.\n",
    "        bsize (int, optional): Block size for raster output. Defaults to 256.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Step 1: Load and validate the model\n",
    "    try:\n",
    "        predictor = TabularPredictor.load(modelpath)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to load the model from {modelpath}: {e}\")\n",
    "\n",
    "    # Perform model validation checks\n",
    "    # Example: Check for necessary metadata or expected feature columns\n",
    "    expected_features = fcol\n",
    "    model_features = predictor.feature_metadata.get_features()\n",
    "    print(f\"Model features: {model_features}\")\n",
    "    print('-'*50)\n",
    "    if not all(feature in model_features for feature in expected_features):\n",
    "        raise ValueError(f\"Model validation failed: Missing required feature columns {expected_features}\")\n",
    "\n",
    "    # If the model passes validation, proceed\n",
    "    print(\"Model loaded and validated successfully.\")\n",
    "\n",
    "    # Step 2: Prepare output paths\n",
    "    outpath = os.path.join(outdir, dirname)\n",
    "    tile_ifile = get_tile_file(tile_files)\n",
    "    tile_odir = os.path.join(outpath, tile_ifile.split('/')[-2])\n",
    "    os.makedirs(tile_odir, exist_ok=True)\n",
    "    tile_ofile = os.path.join(tile_odir, tile_ifile.split('/')[-1].replace('.tif', '_ML.tif'))\n",
    "\n",
    "    # Step 3: Check if output already exists\n",
    "    if not os.path.isfile(tile_ofile):\n",
    "        print(f\"Writing: {tile_ofile} ...\")\n",
    "        \n",
    "        # Step 4: Load prediction data\n",
    "        df = load_prediction_data(fparquet, fcol)\n",
    "        if len(df) != ps * ps:\n",
    "            raise ValueError(f\"Grid size mismatch: Expected {ps * ps}, got {len(df)}\")\n",
    "\n",
    "        # Step 5: Perform predictions and write results\n",
    "        df[f'ml_{yvar}'] = predictor.predict(df[fcol])\n",
    "        df[f'ml_{tcol}'] = df[tcol] - df[f'ml_{yvar}']\n",
    "\n",
    "        write_predictions(predictions=df[f'ml_{tcol}'],  # Residuals\n",
    "                          tile_file=tile_ifile,\n",
    "                          output_raster_path=tile_ofile,\n",
    "                          block_size=(bsize, bsize))\n",
    "    else:\n",
    "        print(f\"{tile_ofile} already exists\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING_AG/\"\n",
    "dirname = \"tlimit120_good_quality\"\n",
    "modelpath = predictor_path = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit120_good_quality/\"\n",
    "idx = 0\n",
    "fparquet,tile_files  = fparquet_list[0],tile_files_list[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model features: ['egm08', 'egm96', 'tdem_hem', 'multi_s1_band1', 'multi_s1_band2', 'multi_s2_band1', 'multi_s2_band2', 'multi_s2_band3']\n",
      "--------------------------------------------------\n",
      "Model loaded and validated successfully.\n",
      "Writing: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING_AG/tlimit120_good_quality/N09E105/N09E105_edem_W84_ML.tif ...\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING_AG/tlimit120_good_quality/N09E105/N09E105_edem_W84_ML.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ag_mbest_predict_workflow(outdir, dirname, modelpath, \n",
    "                              fparquet, tile_files, \n",
    "                              fcol, yvar, tcol, ps, bsize=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import autogluon\n",
    "#print(autogluon.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution(\"autogluon\").version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_path = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit1140_best_quality_135000000/\"\n",
    "predictor_path = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit120_good_quality/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit120_good_quality'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "agx_path = '/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit1140_best_quality_135000000/utils/data/X_val.pkl'\n",
    "agy_path = '/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit1140_best_quality_135000000/utils/data/y_val.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_pickle(agx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case 1: ---------------------------------------------------------------------------\n",
    "AssertionError                            Traceback (most recent call last)\n",
    "Cell In[62], line 1\n",
    "----> 1 best_model = predictor.model_best()\n",
    "      2 print(f\"The best model is: {best_model}\")\n",
    "\n",
    "File ~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:3720, in TabularPredictor.model_best(self)\n",
    "   3709 @property\n",
    "   3710 def model_best(self) -> str:\n",
    "   3711     \"\"\"\n",
    "   3712     Returns the string model name of the best model by validation score that can infer.\n",
    "   3713     This is the same model used during inference when `predictor.predict` is called without specifying a model.\n",
    "   (...)\n",
    "   3718     String model name of the best model\n",
    "   3719     \"\"\"\n",
    "-> 3720     return self._model_best(can_infer=True)\n",
    "\n",
    "File ~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:3729, in TabularPredictor._model_best(self, can_infer)\n",
    "   3727     if self._trainer.model_best in models:\n",
    "   3728         return self._trainer.model_best\n",
    "-> 3729 return self._trainer.get_model_best(can_infer=can_infer)\n",
    "\n",
    "File ~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:1651, in AbstractTrainer.get_model_best(self, can_infer, allow_full, infer_limit, infer_limit_as_child)\n",
    "   1649 models = self.get_model_names(can_infer=can_infer)\n",
    "   1650 if not models:\n",
    "-> 1651     raise AssertionError(\"Trainer has no fit models that can infer.\")\n",
    "   1652 models_full = self.get_models_attribute_dict(models=models, attribute=\"refit_full_parent\")\n",
    "   1653 if not allow_full:\n",
    "\n",
    "AssertionError: Trainer has no fit models that can infer.\n",
    "\n",
    "case 2:\n",
    "\n",
    "{\n",
    "\t\"name\": \"AssertionError\",\n",
    "\t\"message\": \"Trainer has no fit models that can infer.\",\n",
    "\t\"stack\": \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\\n\\u001b[0;31mAssertionError\\u001b[0m                            Traceback (most recent call last)\\nCell \\u001b[0;32mIn[48], line 1\\u001b[0m\\n\\u001b[0;32m----> 1\\u001b[0m d1 \\u001b[38;5;241m=\\u001b[39m \\u001b[43mpredictor\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpredict\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mdf\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\nFile \\u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:2364\\u001b[0m, in \\u001b[0;36mTabularPredictor.predict\\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\\u001b[0m\\n\\u001b[1;32m   2362\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m decision_threshold \\u001b[38;5;129;01mis\\u001b[39;00m \\u001b[38;5;28;01mNone\\u001b[39;00m:\\n\\u001b[1;32m   2363\\u001b[0m     decision_threshold \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mdecision_threshold\\n\\u001b[0;32m-> 2364\\u001b[0m \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43m_learner\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpredict\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mX\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mdata\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mmodel\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mas_pandas\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mas_pandas\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mtransform_features\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mtransform_features\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mdecision_threshold\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mdecision_threshold\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\nFile \\u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:208\\u001b[0m, in \\u001b[0;36mAbstractTabularLearner.predict\\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\\u001b[0m\\n\\u001b[1;32m    206\\u001b[0m     decision_threshold \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;241m0.5\\u001b[39m\\n\\u001b[1;32m    207\\u001b[0m X_index \\u001b[38;5;241m=\\u001b[39m copy\\u001b[38;5;241m.\\u001b[39mdeepcopy(X\\u001b[38;5;241m.\\u001b[39mindex) \\u001b[38;5;28;01mif\\u001b[39;00m as_pandas \\u001b[38;5;28;01melse\\u001b[39;00m \\u001b[38;5;28;01mNone\\u001b[39;00m\\n\\u001b[0;32m--> 208\\u001b[0m y_pred_proba \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpredict_proba\\u001b[49m\\u001b[43m(\\u001b[49m\\n\\u001b[1;32m    209\\u001b[0m \\u001b[43m    \\u001b[49m\\u001b[43mX\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mX\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mmodel\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mas_pandas\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[38;5;28;43;01mFalse\\u001b[39;49;00m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mas_multiclass\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[38;5;28;43;01mFalse\\u001b[39;49;00m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43minverse_transform\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[38;5;28;43;01mFalse\\u001b[39;49;00m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mtransform_features\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mtransform_features\\u001b[49m\\n\\u001b[1;32m    210\\u001b[0m \\u001b[43m\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    211\\u001b[0m problem_type \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mlabel_cleaner\\u001b[38;5;241m.\\u001b[39mproblem_type_transform \\u001b[38;5;129;01mor\\u001b[39;00m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mproblem_type\\n\\u001b[1;32m    212\\u001b[0m y_pred \\u001b[38;5;241m=\\u001b[39m get_pred_from_proba(y_pred_proba\\u001b[38;5;241m=\\u001b[39my_pred_proba, problem_type\\u001b[38;5;241m=\\u001b[39mproblem_type, decision_threshold\\u001b[38;5;241m=\\u001b[39mdecision_threshold)\\n\\nFile \\u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:189\\u001b[0m, in \\u001b[0;36mAbstractTabularLearner.predict_proba\\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\\u001b[0m\\n\\u001b[1;32m    187\\u001b[0m     \\u001b[38;5;28;01mif\\u001b[39;00m transform_features:\\n\\u001b[1;32m    188\\u001b[0m         X \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mtransform_features(X)\\n\\u001b[0;32m--> 189\\u001b[0m     y_pred_proba \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mload_trainer\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43m)\\u001b[49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mpredict_proba\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43mX\\u001b[49m\\u001b[43m,\\u001b[49m\\u001b[43m \\u001b[49m\\u001b[43mmodel\\u001b[49m\\u001b[38;5;241;43m=\\u001b[39;49m\\u001b[43mmodel\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    190\\u001b[0m y_pred_proba \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39m_post_process_predict_proba(\\n\\u001b[1;32m    191\\u001b[0m     y_pred_proba\\u001b[38;5;241m=\\u001b[39my_pred_proba, as_pandas\\u001b[38;5;241m=\\u001b[39mas_pandas, index\\u001b[38;5;241m=\\u001b[39mX_index, as_multiclass\\u001b[38;5;241m=\\u001b[39mas_multiclass, inverse_transform\\u001b[38;5;241m=\\u001b[39minverse_transform\\n\\u001b[1;32m    192\\u001b[0m )\\n\\u001b[1;32m    193\\u001b[0m \\u001b[38;5;28;01mreturn\\u001b[39;00m y_pred_proba\\n\\nFile \\u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:955\\u001b[0m, in \\u001b[0;36mAbstractTrainer.predict_proba\\u001b[0;34m(self, X, model)\\u001b[0m\\n\\u001b[1;32m    953\\u001b[0m \\u001b[38;5;28;01mdef\\u001b[39;00m\\u001b[38;5;250m \\u001b[39m\\u001b[38;5;21mpredict_proba\\u001b[39m(\\u001b[38;5;28mself\\u001b[39m, X: pd\\u001b[38;5;241m.\\u001b[39mDataFrame, model: \\u001b[38;5;28mstr\\u001b[39m \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;01mNone\\u001b[39;00m) \\u001b[38;5;241m-\\u001b[39m\\u001b[38;5;241m>\\u001b[39m np\\u001b[38;5;241m.\\u001b[39mndarray:\\n\\u001b[1;32m    954\\u001b[0m     \\u001b[38;5;28;01mif\\u001b[39;00m model \\u001b[38;5;129;01mis\\u001b[39;00m \\u001b[38;5;28;01mNone\\u001b[39;00m:\\n\\u001b[0;32m--> 955\\u001b[0m         model \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43m_get_best\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\u001b[1;32m    956\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39m_predict_proba_model(X\\u001b[38;5;241m=\\u001b[39mX, model\\u001b[38;5;241m=\\u001b[39mmodel)\\n\\nFile \\u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:962\\u001b[0m, in \\u001b[0;36mAbstractTrainer._get_best\\u001b[0;34m(self)\\u001b[0m\\n\\u001b[1;32m    960\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mmodel_best\\n\\u001b[1;32m    961\\u001b[0m \\u001b[38;5;28;01melse\\u001b[39;00m:\\n\\u001b[0;32m--> 962\\u001b[0m     \\u001b[38;5;28;01mreturn\\u001b[39;00m \\u001b[38;5;28;43mself\\u001b[39;49m\\u001b[38;5;241;43m.\\u001b[39;49m\\u001b[43mget_model_best\\u001b[49m\\u001b[43m(\\u001b[49m\\u001b[43m)\\u001b[49m\\n\\nFile \\u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:1651\\u001b[0m, in \\u001b[0;36mAbstractTrainer.get_model_best\\u001b[0;34m(self, can_infer, allow_full, infer_limit, infer_limit_as_child)\\u001b[0m\\n\\u001b[1;32m   1649\\u001b[0m models \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mget_model_names(can_infer\\u001b[38;5;241m=\\u001b[39mcan_infer)\\n\\u001b[1;32m   1650\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;129;01mnot\\u001b[39;00m models:\\n\\u001b[0;32m-> 1651\\u001b[0m     \\u001b[38;5;28;01mraise\\u001b[39;00m \\u001b[38;5;167;01mAssertionError\\u001b[39;00m(\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mTrainer has no fit models that can infer.\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\\u001b[1;32m   1652\\u001b[0m models_full \\u001b[38;5;241m=\\u001b[39m \\u001b[38;5;28mself\\u001b[39m\\u001b[38;5;241m.\\u001b[39mget_models_attribute_dict(models\\u001b[38;5;241m=\\u001b[39mmodels, attribute\\u001b[38;5;241m=\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m\\u001b[38;5;124mrefit_full_parent\\u001b[39m\\u001b[38;5;124m\\\"\\u001b[39m)\\n\\u001b[1;32m   1653\\u001b[0m \\u001b[38;5;28;01mif\\u001b[39;00m \\u001b[38;5;129;01mnot\\u001b[39;00m allow_full:\\n\\n\\u001b[0;31mAssertionError\\u001b[0m: Trainer has no fit models that can infer.\"\n",
    "}\n",
    "\n",
    "\n",
    "def ag_predict_mbest(predictor_path,df, fcol, yvar, tcol):\n",
    "    #predict using the best model \n",
    "    predictor = TabularPredictor.load(predictor_path)\n",
    "    # check that predict is load, and able to make predictions, and not corrupted or  error  case 1 and 2\n",
    "    df[f'ml_{yvar}'] = predictor.predict(df[fcol])\n",
    "    df[f'ml_{tcol}'] = df[tcol].subtract(df[f'ml_{yvar}'])\n",
    "    return df # we could discard all other variables should we just need to go one with one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ag_predict_mbest(predictor_path,df, fcol, yvar, tcol):\n",
    "    #predict using the best model \n",
    "    predictor = TabularPredictor.load(predictor_path)\n",
    "    # check that predict is load, and able to make predictions, and not corrupted or  error  case 1 and 2\n",
    "    df[f'ml_{yvar}'] = predictor.predict(df[fcol])\n",
    "    df[f'ml_{tcol}'] = df[tcol].subtract(df[f'ml_{yvar}'])\n",
    "    return df # we could discard all other variables should we just need to go one with one\n",
    "\n",
    "def ag_predict_mtopfive(predictor_path,df, fcol, yvar, tcol):\n",
    "    # predict using the top five models \n",
    "    pass \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  ag_predict_mbest(predictor_path,df, fcol, yvar, tcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>egm08</th>\n",
       "      <th>egm96</th>\n",
       "      <th>tdem_hem</th>\n",
       "      <th>multi_s1_band1</th>\n",
       "      <th>multi_s1_band2</th>\n",
       "      <th>multi_s2_band1</th>\n",
       "      <th>multi_s2_band2</th>\n",
       "      <th>multi_s2_band3</th>\n",
       "      <th>edem_w84</th>\n",
       "      <th>tdem_dem__fw</th>\n",
       "      <th>multi_dtm_lidar</th>\n",
       "      <th>zdif</th>\n",
       "      <th>ml_zdif</th>\n",
       "      <th>ml_edem_w84</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.909122</td>\n",
       "      <td>-9.052000</td>\n",
       "      <td>6.867803</td>\n",
       "      <td>-18.357485</td>\n",
       "      <td>-27.563616</td>\n",
       "      <td>0.103014</td>\n",
       "      <td>0.116391</td>\n",
       "      <td>0.128022</td>\n",
       "      <td>-8.909220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.009323</td>\n",
       "      <td>-0.899897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.908708</td>\n",
       "      <td>-9.051620</td>\n",
       "      <td>6.971410</td>\n",
       "      <td>-18.355732</td>\n",
       "      <td>-27.560644</td>\n",
       "      <td>0.103996</td>\n",
       "      <td>0.117849</td>\n",
       "      <td>0.129290</td>\n",
       "      <td>-8.908882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.024690</td>\n",
       "      <td>-0.884192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.908293</td>\n",
       "      <td>-9.051241</td>\n",
       "      <td>7.819718</td>\n",
       "      <td>-18.277824</td>\n",
       "      <td>-27.549456</td>\n",
       "      <td>0.103668</td>\n",
       "      <td>0.117686</td>\n",
       "      <td>0.129413</td>\n",
       "      <td>-8.908545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.036531</td>\n",
       "      <td>-0.872014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.907878</td>\n",
       "      <td>-9.050861</td>\n",
       "      <td>6.184140</td>\n",
       "      <td>-18.199917</td>\n",
       "      <td>-27.538267</td>\n",
       "      <td>0.103340</td>\n",
       "      <td>0.117522</td>\n",
       "      <td>0.129536</td>\n",
       "      <td>-8.908208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.036531</td>\n",
       "      <td>-0.871676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-8.907463</td>\n",
       "      <td>-9.050482</td>\n",
       "      <td>7.063742</td>\n",
       "      <td>-18.128281</td>\n",
       "      <td>-27.599447</td>\n",
       "      <td>0.103559</td>\n",
       "      <td>0.117577</td>\n",
       "      <td>0.129275</td>\n",
       "      <td>-8.907657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.006196</td>\n",
       "      <td>-0.901461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81017996</th>\n",
       "      <td>-2.750880</td>\n",
       "      <td>-2.905636</td>\n",
       "      <td>-32767.000000</td>\n",
       "      <td>-18.797722</td>\n",
       "      <td>-29.085106</td>\n",
       "      <td>0.087559</td>\n",
       "      <td>0.123204</td>\n",
       "      <td>0.146951</td>\n",
       "      <td>-2.750668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.033511</td>\n",
       "      <td>-0.717157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81017997</th>\n",
       "      <td>-2.750468</td>\n",
       "      <td>-2.905227</td>\n",
       "      <td>-32767.000000</td>\n",
       "      <td>-18.593487</td>\n",
       "      <td>-29.173258</td>\n",
       "      <td>0.087127</td>\n",
       "      <td>0.124098</td>\n",
       "      <td>0.146870</td>\n",
       "      <td>-2.750334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.034126</td>\n",
       "      <td>-0.716208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81017998</th>\n",
       "      <td>-2.750057</td>\n",
       "      <td>-2.904818</td>\n",
       "      <td>-32767.000000</td>\n",
       "      <td>-18.651117</td>\n",
       "      <td>-29.158873</td>\n",
       "      <td>0.086188</td>\n",
       "      <td>0.123317</td>\n",
       "      <td>0.146588</td>\n",
       "      <td>-2.749999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.034126</td>\n",
       "      <td>-0.715873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81017999</th>\n",
       "      <td>-2.749645</td>\n",
       "      <td>-2.904409</td>\n",
       "      <td>-32767.000000</td>\n",
       "      <td>-18.708750</td>\n",
       "      <td>-29.144487</td>\n",
       "      <td>0.085248</td>\n",
       "      <td>0.122536</td>\n",
       "      <td>0.146306</td>\n",
       "      <td>-2.749665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.041474</td>\n",
       "      <td>-0.708191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81018000</th>\n",
       "      <td>-2.749233</td>\n",
       "      <td>-2.904000</td>\n",
       "      <td>-32767.000000</td>\n",
       "      <td>-18.595999</td>\n",
       "      <td>-29.052094</td>\n",
       "      <td>0.086005</td>\n",
       "      <td>0.122577</td>\n",
       "      <td>0.146043</td>\n",
       "      <td>-2.749330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.034126</td>\n",
       "      <td>-0.715204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81018001 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             egm08     egm96      tdem_hem  multi_s1_band1  multi_s1_band2  \\\n",
       "0        -8.909122 -9.052000      6.867803      -18.357485      -27.563616   \n",
       "1        -8.908708 -9.051620      6.971410      -18.355732      -27.560644   \n",
       "2        -8.908293 -9.051241      7.819718      -18.277824      -27.549456   \n",
       "3        -8.907878 -9.050861      6.184140      -18.199917      -27.538267   \n",
       "4        -8.907463 -9.050482      7.063742      -18.128281      -27.599447   \n",
       "...            ...       ...           ...             ...             ...   \n",
       "81017996 -2.750880 -2.905636 -32767.000000      -18.797722      -29.085106   \n",
       "81017997 -2.750468 -2.905227 -32767.000000      -18.593487      -29.173258   \n",
       "81017998 -2.750057 -2.904818 -32767.000000      -18.651117      -29.158873   \n",
       "81017999 -2.749645 -2.904409 -32767.000000      -18.708750      -29.144487   \n",
       "81018000 -2.749233 -2.904000 -32767.000000      -18.595999      -29.052094   \n",
       "\n",
       "          multi_s2_band1  multi_s2_band2  multi_s2_band3  edem_w84  \\\n",
       "0               0.103014        0.116391        0.128022 -8.909220   \n",
       "1               0.103996        0.117849        0.129290 -8.908882   \n",
       "2               0.103668        0.117686        0.129413 -8.908545   \n",
       "3               0.103340        0.117522        0.129536 -8.908208   \n",
       "4               0.103559        0.117577        0.129275 -8.907657   \n",
       "...                  ...             ...             ...       ...   \n",
       "81017996        0.087559        0.123204        0.146951 -2.750668   \n",
       "81017997        0.087127        0.124098        0.146870 -2.750334   \n",
       "81017998        0.086188        0.123317        0.146588 -2.749999   \n",
       "81017999        0.085248        0.122536        0.146306 -2.749665   \n",
       "81018000        0.086005        0.122577        0.146043 -2.749330   \n",
       "\n",
       "          tdem_dem__fw  multi_dtm_lidar  zdif   ml_zdif  ml_edem_w84  \n",
       "0                  NaN              NaN   NaN -8.009323    -0.899897  \n",
       "1                  NaN              NaN   NaN -8.024690    -0.884192  \n",
       "2                  NaN              NaN   NaN -8.036531    -0.872014  \n",
       "3                  NaN              NaN   NaN -8.036531    -0.871676  \n",
       "4                  NaN              NaN   NaN -8.006196    -0.901461  \n",
       "...                ...              ...   ...       ...          ...  \n",
       "81017996           NaN              NaN   NaN -2.033511    -0.717157  \n",
       "81017997           NaN              NaN   NaN -2.034126    -0.716208  \n",
       "81017998           NaN              NaN   NaN -2.034126    -0.715873  \n",
       "81017999           NaN              NaN   NaN -2.041474    -0.708191  \n",
       "81018000           NaN              NaN   NaN -2.034126    -0.715204  \n",
       "\n",
       "[81018001 rows x 14 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/autogluon_study/12/zdif/tlimit120_good_quality'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictor = TabularPredictor.load(predictor_path)\n",
    "# predictor.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = predictor.predict(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LightGBMXT_BAG_L1_FULL'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = predictor.predict(df[fcol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81018001,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why the big model is not working? investigate the issue further and send to git hub \n",
    "# make prediction with small model to set up the pipelline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = df[yvar] = df[tcol].subtract(df[rcol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Trainer has no fit models that can infer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_best\u001b[49m()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best model is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:3720\u001b[0m, in \u001b[0;36mTabularPredictor.model_best\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3709\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m   3710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_best\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   3711\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3712\u001b[0m \u001b[38;5;124;03m    Returns the string model name of the best model by validation score that can infer.\u001b[39;00m\n\u001b[1;32m   3713\u001b[0m \u001b[38;5;124;03m    This is the same model used during inference when `predictor.predict` is called without specifying a model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3718\u001b[0m \u001b[38;5;124;03m    String model name of the best model\u001b[39;00m\n\u001b[1;32m   3719\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcan_infer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:3729\u001b[0m, in \u001b[0;36mTabularPredictor._model_best\u001b[0;34m(self, can_infer)\u001b[0m\n\u001b[1;32m   3727\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[1;32m   3728\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mmodel_best\n\u001b[0;32m-> 3729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcan_infer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcan_infer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:1651\u001b[0m, in \u001b[0;36mAbstractTrainer.get_model_best\u001b[0;34m(self, can_infer, allow_full, infer_limit, infer_limit_as_child)\u001b[0m\n\u001b[1;32m   1649\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names(can_infer\u001b[38;5;241m=\u001b[39mcan_infer)\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[0;32m-> 1651\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can infer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1652\u001b[0m models_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_models_attribute_dict(models\u001b[38;5;241m=\u001b[39mmodels, attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefit_full_parent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_full:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Trainer has no fit models that can infer."
     ]
    }
   ],
   "source": [
    "best_model = predictor.model_best()\n",
    "print(f\"The best model is: {best_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method TabularPredictorDeprecatedMixin.get_model_best of <autogluon.tabular.predictor.predictor.TabularPredictor object at 0x73a7b69dfa50>>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.get_model_best\n",
    "<bound method TabularPredictorDeprecatedMixin.get_model_best of <autogluon.tabular.predictor.predictor.TabularPredictor object at 0x73a7b69dfa50>>\n",
    "# how to use that to make predictions on tabular dataset, i have got 1.2 version of autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TabularPredictor' object has no attribute 'save_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_path\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TabularPredictor' object has no attribute 'save_path'"
     ]
    }
   ],
   "source": [
    "predictor.save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`get_model_names` has been deprecated and will be removed in version 1.2. Please use `model_names` instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/common/utils/deprecated_utils.py:123\u001b[0m, in \u001b[0;36mDeprecated.<locals>._decorator.<locals>.patched_func_with_warning_msg\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(obj)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpatched_func_with_warning_msg\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 123\u001b[0m     \u001b[43m_deprecation_warning\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_warning_msg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_warning_msg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion_to_remove\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversion_to_remove\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/common/utils/deprecated_utils.py:25\u001b[0m, in \u001b[0;36m_deprecation_warning\u001b[0;34m(old, new, custom_warning_msg, version_to_remove, error)\u001b[0m\n\u001b[1;32m     22\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m new \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This will raise an error in the future!\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     30\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     31\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: `get_model_names` has been deprecated and will be removed in version 1.2. Please use `model_names` instead"
     ]
    }
   ],
   "source": [
    "print(predictor.get_model_names())\n",
    "ValueError: `get_model_names` has been deprecated and will be removed in version 1.2. Please use `model_names` instead\n",
    "# how to find my version of autogluon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Trainer has no fit models that can infer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:2364\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decision_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_threshold\n\u001b[0;32m-> 2364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_pandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:208\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m    206\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    207\u001b[0m X_index \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(X\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;28;01mif\u001b[39;00m as_pandas \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_multiclass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m problem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_cleaner\u001b[38;5;241m.\u001b[39mproblem_type_transform \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type\n\u001b[1;32m    212\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, problem_type\u001b[38;5;241m=\u001b[39mproblem_type, decision_threshold\u001b[38;5;241m=\u001b[39mdecision_threshold)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:189\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform_features:\n\u001b[1;32m    188\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_features(X)\n\u001b[0;32m--> 189\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_predict_proba(\n\u001b[1;32m    191\u001b[0m     y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, as_pandas\u001b[38;5;241m=\u001b[39mas_pandas, index\u001b[38;5;241m=\u001b[39mX_index, as_multiclass\u001b[38;5;241m=\u001b[39mas_multiclass, inverse_transform\u001b[38;5;241m=\u001b[39minverse_transform\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_proba\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:955\u001b[0m, in \u001b[0;36mAbstractTrainer.predict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd\u001b[38;5;241m.\u001b[39mDataFrame, model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba_model(X\u001b[38;5;241m=\u001b[39mX, model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:962\u001b[0m, in \u001b[0;36mAbstractTrainer._get_best\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:1651\u001b[0m, in \u001b[0;36mAbstractTrainer.get_model_best\u001b[0;34m(self, can_infer, allow_full, infer_limit, infer_limit_as_child)\u001b[0m\n\u001b[1;32m   1649\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names(can_infer\u001b[38;5;241m=\u001b[39mcan_infer)\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[0;32m-> 1651\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can infer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1652\u001b[0m models_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_models_attribute_dict(models\u001b[38;5;241m=\u001b[39mmodels, attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefit_full_parent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_full:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Trainer has no fit models that can infer."
     ]
    }
   ],
   "source": [
    "d1 = predictor.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['egm08', 'egm96', 'tdem_hem', 'multi_s1_band1', 'multi_s1_band2',\n",
       "       'multi_s2_band1', 'multi_s2_band2', 'multi_s2_band3', 'edem_w84',\n",
       "       'tdem_dem__fw', 'multi_dtm_lidar'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Trainer has no fit models that can infer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:2364\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decision_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_threshold\n\u001b[0;32m-> 2364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_pandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:208\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m    206\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    207\u001b[0m X_index \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(X\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;28;01mif\u001b[39;00m as_pandas \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_multiclass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m problem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_cleaner\u001b[38;5;241m.\u001b[39mproblem_type_transform \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type\n\u001b[1;32m    212\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, problem_type\u001b[38;5;241m=\u001b[39mproblem_type, decision_threshold\u001b[38;5;241m=\u001b[39mdecision_threshold)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:189\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform_features:\n\u001b[1;32m    188\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_features(X)\n\u001b[0;32m--> 189\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_predict_proba(\n\u001b[1;32m    191\u001b[0m     y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, as_pandas\u001b[38;5;241m=\u001b[39mas_pandas, index\u001b[38;5;241m=\u001b[39mX_index, as_multiclass\u001b[38;5;241m=\u001b[39mas_multiclass, inverse_transform\u001b[38;5;241m=\u001b[39minverse_transform\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_proba\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:955\u001b[0m, in \u001b[0;36mAbstractTrainer.predict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd\u001b[38;5;241m.\u001b[39mDataFrame, model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba_model(X\u001b[38;5;241m=\u001b[39mX, model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:962\u001b[0m, in \u001b[0;36mAbstractTrainer._get_best\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:1651\u001b[0m, in \u001b[0;36mAbstractTrainer.get_model_best\u001b[0;34m(self, can_infer, allow_full, infer_limit, infer_limit_as_child)\u001b[0m\n\u001b[1;32m   1649\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names(can_infer\u001b[38;5;241m=\u001b[39mcan_infer)\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[0;32m-> 1651\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can infer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1652\u001b[0m models_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_models_attribute_dict(models\u001b[38;5;241m=\u001b[39mmodels, attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefit_full_parent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_full:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Trainer has no fit models that can infer."
     ]
    }
   ],
   "source": [
    "d1 = predictor.predict(df[fcol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_df(model,df,fcol,yvar,tcol):\n",
    "    df[f'ml_{yvar}'] = model.predict(df[fcol])\n",
    "    df[f'ml_{tcol}'] = df[tcol].subtract(df[f'ml_{yvar}'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Trainer has no fit models that can infer.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43myvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtcol\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m, in \u001b[0;36mget_prediction_df\u001b[0;34m(model, df, fcol, yvar, tcol)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_prediction_df\u001b[39m(model,df,fcol,yvar,tcol):\n\u001b[0;32m----> 2\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[tcol]\u001b[38;5;241m.\u001b[39msubtract(df[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mml_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myvar\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/predictor/predictor.py:2364\u001b[0m, in \u001b[0;36mTabularPredictor.predict\u001b[0;34m(self, data, model, as_pandas, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decision_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_threshold\n\u001b[0;32m-> 2364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_pandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecision_threshold\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:208\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict\u001b[0;34m(self, X, model, as_pandas, inverse_transform, transform_features, decision_threshold)\u001b[0m\n\u001b[1;32m    206\u001b[0m     decision_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    207\u001b[0m X_index \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(X\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;28;01mif\u001b[39;00m as_pandas \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_multiclass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform_features\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m problem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_cleaner\u001b[38;5;241m.\u001b[39mproblem_type_transform \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type\n\u001b[1;32m    212\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m get_pred_from_proba(y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, problem_type\u001b[38;5;241m=\u001b[39mproblem_type, decision_threshold\u001b[38;5;241m=\u001b[39mdecision_threshold)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/tabular/learner/abstract_learner.py:189\u001b[0m, in \u001b[0;36mAbstractTabularLearner.predict_proba\u001b[0;34m(self, X, model, as_pandas, as_multiclass, inverse_transform, transform_features)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m transform_features:\n\u001b[1;32m    188\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_features(X)\n\u001b[0;32m--> 189\u001b[0m     y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_process_predict_proba(\n\u001b[1;32m    191\u001b[0m     y_pred_proba\u001b[38;5;241m=\u001b[39my_pred_proba, as_pandas\u001b[38;5;241m=\u001b[39mas_pandas, index\u001b[38;5;241m=\u001b[39mX_index, as_multiclass\u001b[38;5;241m=\u001b[39mas_multiclass, inverse_transform\u001b[38;5;241m=\u001b[39minverse_transform\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred_proba\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:955\u001b[0m, in \u001b[0;36mAbstractTrainer.predict_proba\u001b[0;34m(self, X, model)\u001b[0m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: pd\u001b[38;5;241m.\u001b[39mDataFrame, model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_proba_model(X\u001b[38;5;241m=\u001b[39mX, model\u001b[38;5;241m=\u001b[39mmodel)\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:962\u001b[0m, in \u001b[0;36mAbstractTrainer._get_best\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 962\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/agluon/lib/python3.11/site-packages/autogluon/core/trainer/abstract_trainer.py:1651\u001b[0m, in \u001b[0;36mAbstractTrainer.get_model_best\u001b[0;34m(self, can_infer, allow_full, infer_limit, infer_limit_as_child)\u001b[0m\n\u001b[1;32m   1649\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names(can_infer\u001b[38;5;241m=\u001b[39mcan_infer)\n\u001b[1;32m   1650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[0;32m-> 1651\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can infer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1652\u001b[0m models_full \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_models_attribute_dict(models\u001b[38;5;241m=\u001b[39mmodels, attribute\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrefit_full_parent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_full:\n",
      "\u001b[0;31mAssertionError\u001b[0m: Trainer has no fit models that can infer."
     ]
    }
   ],
   "source": [
    "df = get_prediction_df(predictor,df,fcol,yvar,tcol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = load_cb_model(modelpath)\n",
    "df = get_prediction_df(model,df,fcol,yvar,tcol)\n",
    "\n",
    "tile_ifile = get_tile_file(tile_files)\n",
    "tile_odir = os.path.join(outdir,tile_ifile.split('/')[-2])\n",
    "os.makedirs(tile_odir,exist_ok=True)\n",
    "tile_ofile = os.path.join(tile_odir,tile_ifile.split('/')[-1].replace('.tif','_ML.tif'))\n",
    "write_predictions(predictions=df[f'ml_{tcol}'], #\n",
    "                 tile_file=tile_ifile, \n",
    "                 output_raster_path=tile_ofile, \n",
    "                 block_size=(bsize, bsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['egm08', 'egm96', 'tdem_hem', 'multi_s1_band1', 'multi_s1_band2',\n",
       "       'multi_s2_band1', 'multi_s2_band2', 'multi_s2_band3', 'edem_w84',\n",
       "       'tdem_dem__fw', 'multi_dtm_lidar', 'ml_zdif', 'ml_edem_w84'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['egm08', 'egm96', 'tdem_hem', 'multi_s1_band1', 'multi_s1_band2',\n",
       "       'multi_s2_band1', 'multi_s2_band2', 'multi_s2_band3', 'edem_w84',\n",
       "       'tdem_dem__fw', 'multi_dtm_lidar', 'ml_zdif', 'ml_edem_w84'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E105/N09E105_edem_W84.tif'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tile_ifile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N09E105'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/N09E105/N09E105_edem_W84_ml.tif'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing raster in blocks of size: (512, 512)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/N09E105/N09E105_edem_W84_ml.tif\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
