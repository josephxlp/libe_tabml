{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to know which ones are ensemble:\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from paths import libpath\n",
    "sys.path.append(libpath)\n",
    "from utilsdf import list_files_by_tilenames,tile_files_to_parquet_parallel\n",
    "from uvars import (tilenames_mkd, tilenames_tls,tilenames_rgn,\n",
    "                   tilenames_lidar,RES_DPATH)\n",
    "\n",
    "from uvars import aux_ending12,s1_ending12,s2_ending12,tar_ending12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from pprint import pprint\n",
    "\n",
    "def load_cb_model(model_path):\n",
    "    \"\"\"\n",
    "    Loads a CatBoost model from the given path.\n",
    "    \n",
    "    Parameters:\n",
    "        model_path (str): Path to the CatBoost model file.\n",
    "    \n",
    "    Returns:\n",
    "        CatBoostRegressor: Loaded CatBoost model.\n",
    "    \"\"\"\n",
    "    assert os.path.exists(model_path), f\"{model_path} does not exist\"\n",
    "    model = CatBoostRegressor()\n",
    "    model.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "def predict_with_models(model_dir, df, fcol, yvar, tcol):\n",
    "    \"\"\"\n",
    "    Predicts using all CatBoost models in the specified directory, averages the predictions,\n",
    "    and calculates residuals. Returns the updated dataframe.\n",
    "\n",
    "    Parameters:\n",
    "        model_dir (str): Path to the directory containing the model files.\n",
    "        df (pd.DataFrame): Dataframe containing the features and true values.\n",
    "        fcol (list): List of feature column names to use as predictors.\n",
    "        yvar (str): Target variable name for predictions.\n",
    "        tcol (str): Column name of the true target values to calculate residuals.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Updated dataframe with predictions and residuals.\n",
    "    \"\"\"\n",
    "    # Get all model files ending with \"_model.txt\"\n",
    "    model_files = [os.path.join(model_dir, f) for f in os.listdir(model_dir) if f.endswith(\"_model.txt\")]\n",
    "    print('#--------------------------------------------------#')\n",
    "    pprint(model_files)\n",
    "    assert model_files, f\"No model files found in {model_dir}\"\n",
    "\n",
    "    # Create a CatBoost Pool for the input data\n",
    "    data_pool = Pool(df[fcol])\n",
    "\n",
    "    # Load models and make predictions\n",
    "    predictions = []\n",
    "    for model_file in model_files:\n",
    "        print(f\"Loading model: {model_file}\")\n",
    "        model = load_cb_model(model_file)\n",
    "        y_pred = model.predict(data_pool)\n",
    "        predictions.append(y_pred)\n",
    "\n",
    "    # Calculate the average predictions\n",
    "    y_pred_avg = sum(predictions) / len(predictions)\n",
    "\n",
    "    # Add predictions and residuals to the dataframe\n",
    "    df[f'ml_{yvar}'] = y_pred_avg\n",
    "    df[f'ml_{tcol}'] = df[tcol].subtract(df[f'ml_{yvar}'])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example Usage:\n",
    "# Assuming `df` is your dataframe, `model_dir` is the folder with models, and `fcol` contains feature columns:\n",
    "# model_dir = \"path/to/models\"\n",
    "# df = predict_with_models(model_dir, df, fcol=['feature1', 'feature2'], yvar='target', tcol='actual_target')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from utilsdf import check_fillnulls\n",
    "\n",
    "def get_parquets_and_geotifs_by_tile(RES_DPATH, X, tilenames,vending_all):\n",
    "    fparquet_list,tile_files_list = list_files_by_tilenames(RES_DPATH, X, tilenames)\n",
    "    assert len(fparquet_list) == len(tile_files_list), 'len(fparquet_list) != len(tile_files_list)'\n",
    "    _, fparquet_list = tile_files_to_parquet_parallel(tilenames, \n",
    "                                                       RES_DPATH, \n",
    "                                                       X, \n",
    "                                                       vending_all)\n",
    "    \n",
    "    return fparquet_list,tile_files_list   \n",
    "\n",
    "\n",
    "def write_predictions(predictions, tile_file, output_raster_path, block_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Writes predictions to a new raster file using metadata from an existing tile file in blocks,\n",
    "    optimised for large rasters.\n",
    "\n",
    "    Parameters:\n",
    "    - predictions (array-like): 1D array of predicted values matching the flattened raster size.\n",
    "    - tile_file (str): Path to the raster file from which metadata will be read.\n",
    "    - output_raster_path (str): Path where the new raster file will be saved.\n",
    "    - block_size (tuple): Tuple specifying the block size for processing (default is (128, 128)).\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Read metadata and raster dimensions from the tile file\n",
    "    with rasterio.open(tile_file) as src:\n",
    "        meta = src.meta.copy()\n",
    "        raster_shape = (src.height, src.width)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "\n",
    "    # Reshape predictions to match the raster's dimensions\n",
    "    try:\n",
    "        predictions_reshaped = np.array(predictions).reshape(raster_shape)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Predictions array size {len(predictions)} does not match raster dimensions {raster_shape}.\")\n",
    "\n",
    "    # Update metadata for writing a new raster\n",
    "    meta.update({\n",
    "        \"dtype\": rasterio.float32,  # Ensure predictions are stored as float32\n",
    "        \"count\": 1,  # Single band\n",
    "        \"compress\": \"lzw\"  # Optional: Add compression\n",
    "    })\n",
    "\n",
    "    # Write the new raster in blocks\n",
    "    with rasterio.open(output_raster_path, \"w\", **meta) as dst:\n",
    "        print(f\"Writing raster in blocks of size: {block_size}\")\n",
    "        for y_start in range(0, raster_shape[0], block_size[0]):\n",
    "            for x_start in range(0, raster_shape[1], block_size[1]):\n",
    "                # Calculate window bounds\n",
    "                y_end = min(y_start + block_size[0], raster_shape[0])\n",
    "                x_end = min(x_start + block_size[1], raster_shape[1])\n",
    "                window = ((y_start, y_end), (x_start, x_end))\n",
    "\n",
    "                # Slice the data for the current block\n",
    "                block_data = predictions_reshaped[y_start:y_end, x_start:x_end]\n",
    "\n",
    "                # Write the block to the corresponding window\n",
    "                dst.write(block_data.astype(rasterio.float32), 1, window=rasterio.windows.Window.from_slices(*window))\n",
    "\n",
    "    print(f\"Raster written successfully to {output_raster_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def get_tile_file(tile_files):\n",
    "    tile_file = [i for i in tile_files if i.endswith('edem_W84.tif')] #[0]\n",
    "    assert len(tile_file) == 1, 'len(tile_file) != 1'\n",
    "    tile_file = tile_file[0]\n",
    "    return tile_file\n",
    "\n",
    "def load_prediction_data(fparquet,fcol):\n",
    "    df = pd.read_parquet(fparquet)\n",
    "    df[fcol] = check_fillnulls(df[fcol])\n",
    "    return df\n",
    "\n",
    "def load_cb_model(modelpath):\n",
    "    assert os.path.exists(modelpath), f'{modelpath} does not exist'\n",
    "    model = CatBoostRegressor()\n",
    "    model.load_model(modelpath)\n",
    "    return model\n",
    "\n",
    "def get_prediction_df(model,df,fcol,yvar,tcol):\n",
    "    df[f'ml_{yvar}'] = model.predict(Pool(df[fcol]))\n",
    "    df[f'ml_{tcol}'] = df[tcol].subtract(df[f'ml_{yvar}'])\n",
    "    return df\n",
    "\n",
    "def cb_predict_workflow(outdir,modelpath,fparquet,tile_files,\n",
    "                        fcol,yvar,tcol,ps,bsize=256):\n",
    "    tile_ifile = get_tile_file(tile_files)\n",
    "    tile_odir = os.path.join(outdir,tile_ifile.split('/')[-2])\n",
    "    os.makedirs(tile_odir,exist_ok=True)\n",
    "    tile_ofile = os.path.join(tile_odir,tile_ifile.split('/')[-1].replace('.tif','_ML.tif'))\n",
    "\n",
    "    if not os.path.isfile(tile_ofile):\n",
    "        f'writing:: {tile_ofile} ...'\n",
    "        df = load_prediction_data(fparquet,fcol)\n",
    "        assert len(df) == ps * ps, 'Grid size does not match'\n",
    "        model = load_cb_model(modelpath)\n",
    "        df = get_prediction_df(model,df,fcol,yvar,tcol)\n",
    "\n",
    "        \n",
    "        write_predictions(predictions=df[f'ml_{tcol}'], #\n",
    "                        tile_file=tile_ifile, \n",
    "                        output_raster_path=tile_ofile, \n",
    "                        block_size=(bsize, bsize))\n",
    "    else:\n",
    "        print(f'{tile_ofile} already exists')\n",
    "\n",
    "\n",
    "def cbe_predict_workflow(outdir,model_dir,dirname,fparquet,tile_files,\n",
    "                        fcol,yvar,tcol,ps,bsize=256):\n",
    "    # improve this so that it checks models before loading the data \n",
    "    tile_ifile = get_tile_file(tile_files)\n",
    "    tile_odir = os.path.join(outdir,dirname,tile_ifile.split('/')[-2])\n",
    "    os.makedirs(tile_odir,exist_ok=True)\n",
    "    tile_ofile = os.path.join(tile_odir,tile_ifile.split('/')[-1].replace('.tif','_ML.tif'))\n",
    "\n",
    "    if not os.path.isfile(tile_ofile):\n",
    "        f'writing:: {tile_ofile} ...'\n",
    "        df = load_prediction_data(fparquet,fcol)\n",
    "        assert len(df) == ps * ps, 'Grid size does not match'\n",
    "        #model = load_cb_model(modelpath)\n",
    "        #df = get_prediction_df(model,df,fcol,yvar,tcol)\n",
    "        df = predict_with_models(model_dir, df, fcol, yvar, tcol)\n",
    "\n",
    "        \n",
    "        write_predictions(predictions=df[f'ml_{tcol}'], #\n",
    "                        tile_file=tile_ifile, \n",
    "                        output_raster_path=tile_ofile, \n",
    "                        block_size=(bsize, bsize))\n",
    "\n",
    "\n",
    "# create version b of cbe_predict_workflow, that except list of models rather than a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = \"zdif\"\n",
    "tcol = 'edem_w84'\n",
    "rcol = 'multi_dtm_lidar'\n",
    "fcol = ['egm08', 'egm96', 'tdem_hem', 'multi_s1_band1', 'multi_s1_band2',\n",
    "        'multi_s2_band1', 'multi_s2_band2', 'multi_s2_band3']\n",
    "tar_ending,aux_ending,s1_ending,s2_ending = aux_ending12,s1_ending12,s2_ending12,tar_ending12\n",
    "vending_all = tar_ending+aux_ending+s1_ending+s2_ending\n",
    "X = 12 \n",
    "ps = 9001\n",
    "tilenames = tilenames_mkd\n",
    "bsize = 512 # match with grid size X \n",
    "modelpath = ''\n",
    "outdir = ''\n",
    "#fparquet_list,tile_files_list = get_parquets_and_geotifs_by_tile(RES_DPATH, X, tilenames_mkd,vending_all)\n",
    "\n",
    "# for fparquet,tile_files in zip(fparquet_list,tile_files_list):\n",
    "#     cb_predict_workflow(outdir,modelpath,fparquet,tile_files,\n",
    "#                         fcol,yvar,tcol,ps,bsize=256)\n",
    "    \n",
    "## clean this code, and make it more modular and improve any thing that needs improvement\n",
    "## add timer per cb_predict_workflow \n",
    "# add timer for the whole process too see how long it takes to predict all the tiles\n",
    "# print the timer at the end and write both times to the log file txt t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dir = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter10000_n236435487_eqallxtile/\"\n",
    "\n",
    "yvar = \"zdif\"\n",
    "tcol = 'edem_w84'\n",
    "rcol = 'multi_dtm_lidar'\n",
    "fcol = ['egm08', 'egm96', 'tdem_hem', 'multi_s1_band1', 'multi_s1_band2',\n",
    "        'multi_s2_band1', 'multi_s2_band2', 'multi_s2_band3']\n",
    "tar_ending,aux_ending,s1_ending,s2_ending = aux_ending12,s1_ending12,s2_ending12,tar_ending12\n",
    "vending_all = tar_ending+aux_ending+s1_ending+s2_ending\n",
    "X = 12 \n",
    "ps = 9001\n",
    "tilenames = tilenames_mkd\n",
    "bsize = 512 # match with grid size X \n",
    "# modelpath = ''\n",
    "# outdir = ''\n",
    "# fparquet_list,tile_files_list = get_parquets_and_geotifs_by_tile(RES_DPATH, X, tilenames_mkd,vending_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbe_predict_workflow(outdir,model_dir,dirname,fparquet,tile_files,\n",
    "                        fcol,yvar,tcol,ps,bsize=256):\n",
    "    # improve this so that it checks models before loading the data \n",
    "    tile_ifile = get_tile_file(tile_files)\n",
    "    tile_odir = os.path.join(outdir,dirname,tile_ifile.split('/')[-2])\n",
    "    os.makedirs(tile_odir,exist_ok=True)\n",
    "    tile_ofile = os.path.join(tile_odir,tile_ifile.split('/')[-1].replace('.tif','_ML.tif'))\n",
    "\n",
    "    if not os.path.isfile(tile_ofile):\n",
    "        f'writing:: {tile_ofile} ...'\n",
    "        df = load_prediction_data(fparquet,fcol)\n",
    "        assert len(df) == ps * ps, 'Grid size does not match'\n",
    "        #model = load_cb_model(modelpath)\n",
    "        #df = get_prediction_df(model,df,fcol,yvar,tcol)\n",
    "        df = predict_with_models(model_dir, df, fcol, yvar, tcol)\n",
    "\n",
    "        \n",
    "        write_predictions(predictions=df[f'ml_{tcol}'], #\n",
    "                        tile_file=tile_ifile, \n",
    "                        output_raster_path=tile_ofile, \n",
    "                        block_size=(bsize, bsize))\n",
    "    else:\n",
    "        print(f'{tile_ofile} already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E105/N09E105_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E106/N09E106_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Filtered files count: 8/25\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E104/N10E104_byldem.parquet\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E105/N10E105_byldem.parquet\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E106/N10E106_byldem.parquet\n"
     ]
    }
   ],
   "source": [
    "fparquet_list, tile_files_list = get_parquets_and_geotifs_by_tile(RES_DPATH, X, tilenames, vending_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this to run in parallel\n",
    "# evaluation method - maps and numbers \n",
    "## lidar, tdem, ml\n",
    "## tdem and ml, (diff, rmse, r2) from saga and other pep Bristol figures @"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODELS_DIR =\"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = \"iter100_n1000_eqNonextile_s1\"#\"iter5000_n236435487_eqallxtile\"#\"iter10000_n236435487_eqallxtile\"\n",
    "outdir = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING\"\n",
    "#model_dir = f\"{TRAIN_MODELS_DIR}/train_cb_bysample/12/zdif/{dirname}/\"\n",
    "\n",
    "model_dir = f\"{TRAIN_MODELS_DIR}/cb_train_de_dev/12/zdif/{dirname}\"\n",
    "\n",
    "#fparquet, tile_files  = fparquet_list[0], tile_files_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E105/N09E105_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E106/N09E106_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E105/N10E105_byldem.parquet\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E106/N10E106_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E104/N10E104_byldem.parquet\n",
      "#--------------------------------------------------#\n",
      "['/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt',\n",
      " '/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt']\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/iter100_n1000_eqNonextile_s1/N09E105/N09E105_edem_W84_ML.tif\n",
      "#--------------------------------------------------#\n",
      "['/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt',\n",
      " '/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt']\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/iter100_n1000_eqNonextile_s1/N09E106/N09E106_edem_W84_ML.tif\n",
      "#--------------------------------------------------#\n",
      "['/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt',\n",
      " '/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt']\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/iter100_n1000_eqNonextile_s1/N10E104/N10E104_edem_W84_ML.tif\n",
      "#--------------------------------------------------#\n",
      "['/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt',\n",
      " '/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt']\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/iter100_n1000_eqNonextile_s1/N10E105/N10E105_edem_W84_ML.tif\n",
      "#--------------------------------------------------#\n",
      "['/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt',\n",
      " '/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt']\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_1000_42_model.txt\n",
      "Loading model: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/cb_train_de_dev/12/zdif/iter100_n1000_eqNonextile_s1/catboost_100_42_model.txt\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/iter100_n1000_eqNonextile_s1/N10E106/N10E106_edem_W84_ML.tif\n"
     ]
    }
   ],
   "source": [
    "fparquet_list, tile_files_list = get_parquets_and_geotifs_by_tile(RES_DPATH, X, tilenames, vending_all)\n",
    "for fparquet,tile_files in zip(fparquet_list,tile_files_list):\n",
    "    cbe_predict_workflow(outdir,model_dir,dirname,fparquet,tile_files,\n",
    "                        fcol,yvar,tcol,ps,bsize=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/iter10000_n236435487_eqallxtile/N09E105/N09E105_edem_W84_ML.tif already exists\n"
     ]
    }
   ],
   "source": [
    "# option one accpts folder\n",
    "# option two accepts the files as model txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbe_predict_workflow_vb(outdir, model_list, dirname, fparquet, tile_files, \n",
    "                            fcol, yvar, tcol, ps, bsize=256):\n",
    "    \"\"\"\n",
    "    Workflow for prediction that accepts a list of models rather than a directory.\n",
    "    \n",
    "    Parameters:\n",
    "    - outdir (str): Output directory path.\n",
    "    - model_list (list): List of paths to CatBoost model files.\n",
    "    - dirname (str): Name of the subdirectory for the output.\n",
    "    - fparquet (str): Path to the Parquet file containing input data.\n",
    "    - tile_files (list): List of tile files.\n",
    "    - fcol (str): Name of the feature column.\n",
    "    - yvar (str): Name of the target variable.\n",
    "    - tcol (str): Name of the terrain column.\n",
    "    - ps (int): Grid size.\n",
    "    - bsize (int): Block size for writing raster files. Default is 256.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    tile_ifile = get_tile_file(tile_files)\n",
    "    tile_odir = os.path.join(outdir, dirname, tile_ifile.split('/')[-2])\n",
    "    os.makedirs(tile_odir, exist_ok=True)\n",
    "    tile_ofile = os.path.join(tile_odir, tile_ifile.split('/')[-1].replace('.tif', '_ML.tif'))\n",
    "\n",
    "    if not os.path.isfile(tile_ofile):\n",
    "        print(f'Writing: {tile_ofile} ...')\n",
    "        df = load_prediction_data(fparquet, fcol)\n",
    "        assert len(df) == ps * ps, 'Grid size does not match'\n",
    "\n",
    "        # Load each model and apply predictions sequentially\n",
    "        for model_path in model_list:\n",
    "            assert os.path.exists(model_path), f'{model_path} does not exist'\n",
    "            model = load_cb_model(model_path)\n",
    "            df = get_prediction_df(model, df, fcol, yvar, tcol)\n",
    "\n",
    "        write_predictions(predictions=df[f'ml_{tcol}'],  #\n",
    "                          tile_file=tile_ifile, \n",
    "                          output_raster_path=tile_ofile, \n",
    "                          block_size=(bsize, bsize))\n",
    "    else:\n",
    "        print(f'{tile_ofile} already exists')\n",
    "\n",
    "\n",
    "# instead of averaging do all posible compinations, and pick the best model using the valid set\n",
    "# plot all the scores \n",
    "# BMA average in the readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter5000_n236435487_eqallxtile/\"\n",
    "model_dir = \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter10000_n236435487_eqallxtile/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list =  \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list_e = [\n",
    "    \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter20000_n81000000_eq6xtile/catboost_20000_42_model.txt\",\n",
    "    \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter10000_n81000000_eq6xtile/catboost_10000_42_model.txt\",\n",
    "    \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter5000_n236435487_eqallxtile/catboost_5000_13_model.txt\",\n",
    "    \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter2000_n236435487_eqallxtile/catboost_2000_21_model.txt\",\n",
    "    \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter5000_n236435487_eqallxtile/catboost_5000_43_model.txt\",\n",
    "    \"/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/MODELS/train_cb_bysample/12/zdif/iter10000_n236435487_eqallxtile/catboost_10000_43_model.txt\"\n",
    "]\n",
    "dirname_model_list_e =  \"model_list_e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E105/N09E105_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E106/N09E106_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E104/N10E104_byldem.parquet\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E105/N10E105_byldem.parquet\n",
      "Filtered files count: 8/25\n",
      "Parquet file already exists: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E106/N10E106_byldem.parquet\n"
     ]
    }
   ],
   "source": [
    "outdir = '/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING'\n",
    "bsize = 256\n",
    "fparquet_list, tile_files_list = get_parquets_and_geotifs_by_tile(RES_DPATH, X, tilenames, vending_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E105/N09E105_byldem.parquet\n",
      "/media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N09E105/N09E105_edem_W84_ML.tif already exists\n",
      "1 /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N09E106/N09E106_byldem.parquet\n",
      "Writing: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N09E106/N09E106_edem_W84_ML.tif ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N09E106/N09E106_edem_W84_ML.tif\n",
      "2 /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E104/N10E104_byldem.parquet\n",
      "Writing: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N10E104/N10E104_edem_W84_ML.tif ...\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N10E104/N10E104_edem_W84_ML.tif\n",
      "3 /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E105/N10E105_byldem.parquet\n",
      "Writing: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N10E105/N10E105_edem_W84_ML.tif ...\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N10E105/N10E105_edem_W84_ML.tif\n",
      "4 /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/TILES12/N10E106/N10E106_byldem.parquet\n",
      "Writing: /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N10E106/N10E106_edem_W84_ML.tif ...\n",
      "Writing raster in blocks of size: (256, 256)\n",
      "Raster written successfully to /media/ljp238/12TBWolf/RSPROX/OUTPUT_TILES/PREDICTIONS/TESTING/model_list_e/N10E106/N10E106_edem_W84_ML.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, (fparquet,tile_files) in enumerate(zip(fparquet_list,tile_files_list)):\n",
    "    print(f'{i} {fparquet}')\n",
    "    #if i > 0: break\n",
    "    cbe_predict_workflow_vb(outdir=outdir, \n",
    "                            model_list=model_list_e, \n",
    "                            dirname=dirname_model_list_e, \n",
    "                            fparquet=fparquet, \n",
    "                            tile_files=tile_files, \n",
    "                            fcol=fcol, yvar=yvar, \n",
    "                            tcol=tcol, ps=ps, \n",
    "                            bsize=bsize)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
