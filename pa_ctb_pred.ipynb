{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get the Models by X - all of them \n",
    "- load them and preidct : from the other pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsml import train_model\n",
    "from utilsdf import list_files_by_tilenames\n",
    "from uvars import tilenames_lidar,RES_DPATH\n",
    "from utilsdf import assign_nulls, fillna,dropnulls_bycol,check_fillnulls, list_files_by_tilenames\n",
    "from uvars import s1_fnames, s2_fnames,aux_names\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "import os \n",
    "from catboost import CatBoostRegressor\n",
    "import rasterio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write_predictions_to_raster(predictions, tile_file, output_raster_path, block_size=256)\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def write_predictions_to_raster(predictions, tile_file, output_raster_path, block_size=256):\n",
    "    \"\"\"\n",
    "    Writes predictions to a new raster file in blocks of specified size using metadata from an existing tile file.\n",
    "    \n",
    "    Parameters:\n",
    "    - predictions (array-like): 1D array of predicted values matching the flattened raster size.\n",
    "    - tile_file (str): Path to the raster file from which metadata will be read.\n",
    "    - output_raster_path (str): Path where the new raster file will be saved.\n",
    "    - block_size (int): The size of the block to write at once. Default is 256.\n",
    "    \n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Read metadata from the tile file\n",
    "    with rasterio.open(tile_file) as src:\n",
    "        meta = src.meta.copy()\n",
    "        raster_shape = (src.height, src.width)\n",
    "        transform = src.transform\n",
    "        crs = src.crs\n",
    "\n",
    "    # Reshape predictions to match the raster's dimensions\n",
    "    try:\n",
    "        predictions_reshaped = np.array(predictions).reshape(raster_shape)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Predictions array size {len(predictions)} does not match raster dimensions {raster_shape}.\")\n",
    "\n",
    "    # Update metadata for writing a new raster\n",
    "    meta.update({\n",
    "        \"dtype\": rasterio.float32,  # Ensure predictions are stored as float32\n",
    "        \"count\": 1,  # Single band\n",
    "        \"compress\": \"lzw\"  # Optional: Add compression\n",
    "    })\n",
    "\n",
    "    # Function to write data in blocks\n",
    "    def write_in_blocks(predictions_reshaped, block_size, dst):\n",
    "        for i in range(0, predictions_reshaped.shape[0], block_size):\n",
    "            for j in range(0, predictions_reshaped.shape[1], block_size):\n",
    "                block = predictions_reshaped[i:i+block_size, j:j+block_size]\n",
    "                dst.write(block.astype(rasterio.float32), 1, window=rasterio.windows.Window(j, i, block.shape[1], block.shape[0]))\n",
    "                print(f\"Written block ({i}, {j}) to the raster.\")\n",
    "\n",
    "    # Write the new raster in blocks\n",
    "    with rasterio.open(output_raster_path, \"w\", **meta) as dst:\n",
    "        write_in_blocks(predictions_reshaped, block_size, dst)\n",
    "\n",
    "    print(f\"New raster saved to {output_raster_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_model_files_by_group(directory, n=3):\n",
    "    model_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('model.txt'):\n",
    "                model_files.append(os.path.join(root, file))\n",
    "    \n",
    "    # Grouping files into sublists of size n\n",
    "    grouped_files = [model_files[i:i+n] for i in range(0, len(model_files), n)]\n",
    "    \n",
    "    return grouped_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = 90\n",
    "pathx = f\"/home/ljp238/Documents/UoE/libe_tabml/output/pa_ctb_traine/{X}\"\n",
    "model_filesx = find_model_files_by_group(pathx, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ljp238/Documents/UoE/libe_tabml/output/pa_ctb_traine/90/1000/output/pa_ctb_traine/90/2000/output/pa_ctb_traine/90/5000/N8640000_zdif_90m_catboost_5000_21_model.txt',\n",
       " '/home/ljp238/Documents/UoE/libe_tabml/output/pa_ctb_traine/90/1000/output/pa_ctb_traine/90/2000/output/pa_ctb_traine/90/5000/N8640000_zdif_90m_catboost_5000_13_model.txt',\n",
       " '/home/ljp238/Documents/UoE/libe_tabml/output/pa_ctb_traine/90/1000/output/pa_ctb_traine/90/2000/output/pa_ctb_traine/90/5000/N8640000_zdif_90m_catboost_5000_43_model.txt']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_filesx[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7b6c25a0b150>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelpath = model_filesx[1][0]\n",
    "model = CatBoostRegressor()\n",
    "model.load_model(modelpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S: GEN PARQUETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from utilsdf import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "def get_tile_names(tile_files, tilename,X):\n",
    "    tile_names = [os.path.basename(i).replace('.tif', '') for i in tile_files]\n",
    "    tile_names = [i.replace(f'_{X}','') for i in tile_names]\n",
    "    tile_names = [i.replace(f'{tilename}_','').lower() for i in tile_names]\n",
    "    return tile_names\n",
    "\n",
    "def get_tile_files(DPATH, X, tilename):\n",
    "    TILESX = f\"{DPATH}{X}\"\n",
    "    tile_dpath = f'{TILESX}/{tilename}'\n",
    "    fparquet = f'{tile_dpath}/{tilename}_byldem.parquet'\n",
    "    tile_files = glob(f'{tile_dpath}/*.tif')\n",
    "    return tile_files, fparquet\n",
    "\n",
    "def filter_files_by_endingwith(files, var_ending):\n",
    "    filtered_files = []\n",
    "    for ending in var_ending:\n",
    "        matched_files = [f for f in files if f.endswith(ending)]\n",
    "        #filtered_files.append(matched_files)\n",
    "        filtered_files.extend(matched_files)\n",
    "    print(f\"Filtered files count: {len(filtered_files)}/{len(files)}\")\n",
    "    return filtered_files\n",
    "\n",
    "def pathlist2df(vpaths, vnames):\n",
    "    \"\"\"\n",
    "    Reads raster files from a list of paths into a single DataFrame, where each file (or band) is a column.\n",
    "    Handles NoData values by replacing them with np.nan.\n",
    "\n",
    "    Parameters:\n",
    "        vpaths (list): List of file paths to raster datasets.\n",
    "        vnames (list): List of names to use for the columns in the DataFrame. Must match the number of rasters.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame where each column corresponds to a raster or band from the input list.\n",
    "    \"\"\"\n",
    "    if len(vpaths) != len(vnames):\n",
    "        raise ValueError(\"The length of vpaths and vnames must be the same.\")\n",
    "\n",
    "    data_dict = {}  # To hold the raster data\n",
    "    for path, vname in zip(vpaths, vnames):\n",
    "        with rasterio.open(path) as src:\n",
    "            #meta = src.meta\n",
    "            nodata = src.nodata  # Get NoData value\n",
    "            raster_data = src.read()  # Read all bands\n",
    "            nbands = src.count\n",
    "\n",
    "            if nbands > 1:  # Multiband raster\n",
    "                for band_idx in range(raster_data.shape[0]):\n",
    "                    column_name = f\"{vname}_band{band_idx + 1}\"  # Add band suffix\n",
    "                    band_data = raster_data[band_idx].flatten()  # Flatten the 2D array into 1D\n",
    "                    band_data = np.where(band_data == nodata, np.nan, band_data)  # Replace NoData with np.nan\n",
    "                    data_dict[column_name] = band_data\n",
    "            else:  # Single-band raster\n",
    "                column_name = vname  # Use vname directly\n",
    "                raster_data = raster_data.flatten()\n",
    "                raster_data = np.where(raster_data == nodata, np.nan, raster_data)\n",
    "                data_dict[column_name] = raster_data\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data_dict)\n",
    "    df = df.astype(np.float32)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uvars import RES_DPATH, tilenames_lidar\n",
    "from uvars import aux_ending90,s1_ending90,s2_ending90,tar_ending90\n",
    "tar_ending,aux_ending,s1_ending,s2_ending = aux_ending90,s1_ending90,s2_ending90,tar_ending90\n",
    "vending_all = tar_ending+aux_ending+s1_ending+s2_ending\n",
    "tilename = tilenames_lidar[0]\n",
    "DPATH = RES_DPATH\n",
    "X = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered files count: 9/13\n"
     ]
    }
   ],
   "source": [
    "tile_files, fparquet = get_tile_files(DPATH, X, tilename)\n",
    "tile_files = filter_files_by_endingwith(tile_files, vending_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_EGM08_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_EGM96_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_tdem_HEM_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_multi_S1_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_multi_S2RGB_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_edem_W84_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_tdem_DEM__RIO_0_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_tdem_DEM__Fw_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_multi_DTM_LiDAR_90.tif']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered files count: 9/13\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tile_files, fparquet \u001b[38;5;241m=\u001b[39m get_tile_files(DPATH, X, tilename)\n\u001b[1;32m      2\u001b[0m tile_files \u001b[38;5;241m=\u001b[39m filter_files_by_endingwith(tile_files, vending_all)\n\u001b[0;32m----> 3\u001b[0m tile_names \u001b[38;5;241m=\u001b[39m \u001b[43mget_tile_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtile_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m tile_files,tile_names\n\u001b[1;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pathlist2df(tile_files, tile_names)\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mget_tile_names\u001b[0;34m(tile_files, tilename, X)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_tile_names\u001b[39m(tile_files, tilename,X):\n\u001b[0;32m----> 7\u001b[0m     tile_names \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.tif\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtile_files\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m     tile_names \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tile_names]\n\u001b[1;32m      9\u001b[0m     tile_names \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tile_names]\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_tile_names\u001b[39m(tile_files, tilename,X):\n\u001b[0;32m----> 7\u001b[0m     tile_names \u001b[38;5;241m=\u001b[39m [\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tile_files]\n\u001b[1;32m      8\u001b[0m     tile_names \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tile_names]\n\u001b[1;32m      9\u001b[0m     tile_names \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tile_names]\n",
      "File \u001b[0;32m<frozen posixpath>:142\u001b[0m, in \u001b[0;36mbasename\u001b[0;34m(p)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
     ]
    }
   ],
   "source": [
    "\n",
    "tile_names = get_tile_names(tile_files, tilename,X)\n",
    "tile_files,tile_names\n",
    "df = pathlist2df(tile_files, tile_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E: gENERATE PARQUETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE byldem.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import shutil\n",
    "import os \n",
    "X = 12#30#90 \n",
    "\n",
    "prq_pattern = f\"/media/ljp238/12TBWolf/RSPROX/TILES{X}/*/*byldem.parquet\"\n",
    "prq_files = glob(prq_pattern)\n",
    "#for i in prq_files: os.remove(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK byldem.parquet \n",
    "- column by file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import shutil\n",
    "import os \n",
    "import pandas as pd \n",
    "X = 12#30#90 \n",
    "prq_pattern = f\"/media/ljp238/12TBWolf/RSPROX/TILES{X}/*/*byldem.parquet\"\n",
    "prq_files = glob(prq_pattern)\n",
    "\n",
    "for i, prq in enumerate(prq_files):\n",
    "    if i > 0: break\n",
    "    df = pd.read_parquet(prq)\n",
    "    print(prq)\n",
    "    print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "egm08                      0\n",
       "egm96                      0\n",
       "tdem_hem                   0\n",
       "multi_s1_band1             0\n",
       "multi_s1_band2             0\n",
       "multi_s2rgb_band1          0\n",
       "multi_s2rgb_band2          0\n",
       "multi_s2rgb_band3          0\n",
       "multi_s2rgb_band4          0\n",
       "multi_s2rgb_band5          0\n",
       "multi_s2rgb_band6          0\n",
       "multi_s2rgb_band7          0\n",
       "multi_s2rgb_band8          0\n",
       "multi_s2rgb_band9          0\n",
       "multi_s2rgb_band10         0\n",
       "multi_s2rgb_band11         0\n",
       "edem_w84                   0\n",
       "tdem_dem__rio_0            0\n",
       "tdem_dem__fw          183997\n",
       "multi_dtm_lidar            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() # the error is in resampling to 30,90 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that data and column match per df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X == 90:\n",
    "    assert len(df) == 1200*1200, ' Grid does not match'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440000, 20)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# goal train model 90 and predduct before 12pm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['egm08',\n",
       " 'egm96',\n",
       " 'tdem_hem',\n",
       " 'multi_s1',\n",
       " 'multi_s2rgb',\n",
       " 'edem_w84',\n",
       " 'tdem_dem__rio_0',\n",
       " 'tdem_dem__fw',\n",
       " 'multi_dtm_lidar']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tile_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything is wrong here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_byldem.parquet\n"
     ]
    }
   ],
   "source": [
    "tfcols = ['edem', 'ldem', 'egm08', 'egm96', 'hem', 'vv', 'vh', 'red', 'green', 'blue', 'nir', 'swir1']\n",
    "fcols = ['egm08', 'egm96', 'hem', 'vv', 'vh', 'red', 'green', 'blue', 'nir', 'swir1']\n",
    "tcol = 'edem'\n",
    "\n",
    "tilenames = tilenames_lidar\n",
    "fparquet_list,tile_files_list = list_files_by_tilenames(RES_DPATH, X, tilenames)\n",
    "L = len(fparquet_list)\n",
    "print(L)\n",
    "for idx in range(L):\n",
    "    if idx > 0 : break\n",
    "    fparquet,tile_files = fparquet_list[idx],tile_files_list[idx]\n",
    "    print(fparquet)\n",
    "    df = pd.read_parquet(fparquet_list, columns=tfcols)\n",
    "    df[fcols] = check_fillnulls(df[fcols]) # only fill fcols -this correct?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640000, 12)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zdif'] = model.predict(df[fcols])\n",
    "df['ldem_ml'] = df['edem'].subtract(df['zdif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_edem_W84_90.tif',\n",
       " '/media/ljp238/12TBWolf/RSPROX/TILES90/N09E105/N09E105_edem_W84_90__ML90.tif')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_ifile = [i for i in tile_files if 'edem_W84' in i][0]\n",
    "tile_ofile = tile_ifile.replace('.tif', f'__ML{X}.tif')\n",
    "tile_ifile,tile_ofile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Predictions array size 8640000 does not match raster dimensions (1200, 1200).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 27\u001b[0m, in \u001b[0;36mwrite_predictions_to_raster\u001b[0;34m(predictions, tile_file, output_raster_path, block_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m     predictions_reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraster_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 8640000 into shape (1200,1200)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwrite_predictions_to_raster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mldem_ml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtile_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtile_ifile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moutput_raster_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtile_ofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[55], line 29\u001b[0m, in \u001b[0;36mwrite_predictions_to_raster\u001b[0;34m(predictions, tile_file, output_raster_path, block_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m     predictions_reshaped \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predictions)\u001b[38;5;241m.\u001b[39mreshape(raster_shape)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions array size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(predictions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match raster dimensions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mraster_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Update metadata for writing a new raster\u001b[39;00m\n\u001b[1;32m     32\u001b[0m meta\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: rasterio\u001b[38;5;241m.\u001b[39mfloat32,  \u001b[38;5;66;03m# Ensure predictions are stored as float32\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Single band\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlzw\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Optional: Add compression\u001b[39;00m\n\u001b[1;32m     36\u001b[0m })\n",
      "\u001b[0;31mValueError\u001b[0m: Predictions array size 8640000 does not match raster dimensions (1200, 1200)."
     ]
    }
   ],
   "source": [
    "\n",
    "write_predictions_to_raster(predictions = np.array(df['ldem_ml']), \n",
    "                            tile_file = tile_ifile,\n",
    "                            output_raster_path =tile_ofile,\n",
    "                            block_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3600 * 3600 # 30m 12960000 check this for my outing df \n",
    "# 1200*1200 # 90m 1440000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and preprocessing (1min)\n",
    "# prediction and subtraction (20sec)\n",
    "# write_predictions_to_raster (1min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
